import jax
import jax.numpy as jnp

import equinox as eqx

from jax_tqdm import scan_tqdm
from flows import partition


def train(
    key,
    flow,
    get_sample,
    steps,
    optimizer=None,
    batch_size=1,
):
    """ train using monte carlo samples generated by `get_sample` """
    params, static = partition(flow)

    def get_batch(key):
        keys = jax.random.split(key, batch_size)
        return jax.vmap(get_sample)(keys)

    def loss_fn(params, key, _):
        flow = eqx.combine(params, static)
        batch = get_batch(key)
        log_q = jax.vmap(
            lambda x: flow.log_prob(x[0], condition=x[1])
        )(batch)
        return -jnp.mean(log_q)

    state = optimizer.init(params)

    @scan_tqdm(steps, desc='train')
    @eqx.filter_jit
    def update(carry, step):
        key, params, state = carry
        key, _key = jax.random.split(key)
        loss, grad = eqx.filter_value_and_grad(loss_fn)(params, _key, step)
        updates, state = optimizer.update(grad, state, params)
        params = eqx.apply_updates(params, updates)
        return (key, params, state), loss

    (key, params, state), losses = jax.lax.scan(
        update, (key, params, state), jnp.arange(steps),
    )
    flow = eqx.combine(params, static)

    return flow, losses
